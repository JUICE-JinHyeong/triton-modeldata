{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f226ad44-dc7c-4ea8-9d0c-6de9dd2b0a44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 11:04:37.658302: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 11:04:37.992662: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 11:04:37.994281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 11:04:39.193448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "# import matplotlib.pyplot as plt\n",
    "# import urllib.request\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f046e56-b9ad-41cc-be82-1e6144e8a9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading JPype1-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (464 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.2/464.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml>=4.1.0 (from konlpy)\n",
      "  Downloading lxml-4.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.11/site-packages (from konlpy) (1.23.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
      "Installing collected packages: lxml, JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.1 konlpy-0.6.0 lxml-4.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120abd2c-4076-4d94-9640-dd62d4402d44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow  2.12.0\n",
      "keras 2.12.0\n",
      "numpy 1.23.5\n",
      "padnas 2.0.2\n",
      "h5py 3.8.0\n",
      "konlpy 0.6.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow\n",
    "# import keras\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import h5py\n",
    "# import konlpy \n",
    "\n",
    "# print('tensorflow ',tensorflow.__version__)\n",
    "# print('keras', keras.__version__)\n",
    "# print('numpy', np.__version__)\n",
    "# print('padnas', pd.__version__)\n",
    "# print('h5py', h5py.__version__)\n",
    "# print('konlpy', konlpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6df72a5-79f2-4ddb-b03c-a1745e650a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class psng_predict_all:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        path = ''\n",
    "        self.loaded_model = load_model(f'{path}new_model_01_v2.h5')\n",
    "        train_data = pd.read_csv(f'{path}train_data_main.csv', encoding='euc-kr')\n",
    "        test_data = pd.read_csv(f'{path}test_data_main.csv', encoding='euc-kr')\n",
    "        X_train = train_data['tokenized'].apply(eval).values\n",
    "        self.X_test = test_data['tokenized'].apply(eval).values\n",
    "        self.y_test = np.array(test_data['label'].values)\n",
    "        self.X_test_tkd = None\n",
    "        vocab_size = 87912\n",
    "        self.tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
    "        self.tokenizer.fit_on_texts(X_train)\n",
    "        self.max_len = 250\n",
    "\n",
    "    def preprocessing(self):\n",
    "        okt = Okt()\n",
    "        R_frm = self.df.copy()\n",
    "        R_frm['리뷰'] = R_frm['리뷰'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", regex=True)\n",
    "        R_frm['리뷰'].replace('', np.nan, inplace=True)\n",
    "        R_frm['리뷰'] = R_frm['리뷰'].astype(str)\n",
    "        stopwords = ['도', '는', '다', '의', '가', '이', '은',\n",
    "                     '한', '에', '하', '고', '을', '를', '인', '듯',\n",
    "                     '과', '와', '네', '들', '듯', '지', '임', '게',\n",
    "                     '는', '이', '했', '슴', '음', '것', '거', '로',\n",
    "                     '들', '거', '곳', '분', '원', '더', '왜', '해',\n",
    "                     '수', '할', '그', '함', '돈', '번', '두', '개',\n",
    "                     '건', '내', '저', '만', '갈', '걸', '제', '명',\n",
    "                     '분',\n",
    "                     '인데', '이가', '했었', '해서',\n",
    "                     '습니다', '했는데', '입니다']\n",
    "\n",
    "        okt = Okt()\n",
    "        R_frm['tokenized'] = R_frm['리뷰'].apply(okt.pos)\n",
    "        R_frm['tokenized'] = R_frm['tokenized'].apply(\n",
    "            lambda x: [word for word, shape in x if shape in ['Verb', 'Adjective', 'Noun', 'VerbPrefix'] if word not in stopwords])\n",
    "        R_pred = R_frm['tokenized'].values\n",
    "        return R_pred\n",
    "\n",
    "    def model_test(self):\n",
    "        tokenizer = self.tokenizer\n",
    "        X_test = tokenizer.texts_to_sequences(self.X_test)\n",
    "        y_test = self.y_test\n",
    "        X_test = pad_sequences(X_test, maxlen=self.max_len)\n",
    "        print(\"\\n 테스트 정확도: %.4f\" % (self.loaded_model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "    def word_index(self):\n",
    "        tokenizer = self.tokenizer\n",
    "        print(tokenizer.word_index)\n",
    "\n",
    "    def predict(self):\n",
    "        R_pred = self.preprocessing()\n",
    "        max_len = self.max_len\n",
    "        tokenizer = self.tokenizer\n",
    "        result = []\n",
    "        pred = tokenizer.texts_to_sequences(R_pred)\n",
    "        pred = pad_sequences(pred, maxlen=max_len)\n",
    "        score = self.loaded_model.predict(pred)\n",
    "        return score\n",
    "\n",
    "    def prediction(self):\n",
    "        result = []\n",
    "        score = self.predict()\n",
    "        for num in range(len(score)):\n",
    "            if score[num][0] > 0.9:\n",
    "                result.append('0')\n",
    "            elif score[num][0] < 0.1:\n",
    "                result.append('1')\n",
    "            else:\n",
    "                result.append('2')\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbbfcc8-b4f2-44ff-9de3-0dac12522a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('model_test_data.xlsx')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df34c9b4-5bd0-49c6-ac3b-5eb0d9927224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 14:56:04.813637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-06-04 14:56:04.815345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-06-04 14:56:04.816585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "test = psng_predict_all(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1f189e7-58ce-4b05-b669-8683804ae813",
   "metadata": {},
   "outputs": [
    {
     "ename": "JVMNotFoundException",
     "evalue": "No JVM shared library file (libjvm.so) found. Try setting up the JAVA_HOME environment variable properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJVMNotFoundException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 64\u001b[0m, in \u001b[0;36mpsng_predict_all.prediction\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     63\u001b[0m     result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 64\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(score)):\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m score[num][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m:\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mpsng_predict_all.predict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     R_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len\n\u001b[1;32m     55\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mpsng_predict_all.preprocessing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocessing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     okt \u001b[38;5;241m=\u001b[39m \u001b[43mOkt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     R_frm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     20\u001b[0m     R_frm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m R_frm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/konlpy/tag/_okt.py:51\u001b[0m, in \u001b[0;36mOkt.__init__\u001b[0;34m(self, jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, jvmpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_heap_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jpype\u001b[38;5;241m.\u001b[39misJVMStarted():\n\u001b[0;32m---> 51\u001b[0m         \u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_jvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvmpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_heap_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     oktJavaPackage \u001b[38;5;241m=\u001b[39m jpype\u001b[38;5;241m.\u001b[39mJPackage(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkr.lucypark.okt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m     OktInterfaceJavaClass \u001b[38;5;241m=\u001b[39m oktJavaPackage\u001b[38;5;241m.\u001b[39mOktInterface\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/konlpy/jvm.py:55\u001b[0m, in \u001b[0;36minit_jvm\u001b[0;34m(jvmpath, max_heap_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m args \u001b[38;5;241m=\u001b[39m [javadir, os\u001b[38;5;241m.\u001b[39msep]\n\u001b[1;32m     53\u001b[0m classpath \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m folder_suffix]\n\u001b[0;32m---> 55\u001b[0m jvmpath \u001b[38;5;241m=\u001b[39m jvmpath \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDefaultJVMPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# NOTE: Temporary patch for Issue #76. Erase when possible.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m'\u001b[39m\\\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m jvmpath\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.8.0\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\\\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m jvmpath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibjvm.dylib\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/jpype/_jvmfinder.py:74\u001b[0m, in \u001b[0;36mgetDefaultJVMPath\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     finder \u001b[38;5;241m=\u001b[39m LinuxJVMFinder()\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfinder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_jvm_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/jpype/_jvmfinder.py:212\u001b[0m, in \u001b[0;36mJVMFinder.get_jvm_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jvm_notsupport_ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jvm_notsupport_ext\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m JVMNotFoundException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo JVM shared library file (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound. Try setting up the JAVA_HOME \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable properly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m                            \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libfile))\n",
      "\u001b[0;31mJVMNotFoundException\u001b[0m: No JVM shared library file (libjvm.so) found. Try setting up the JAVA_HOME environment variable properly."
     ]
    }
   ],
   "source": [
    "test.prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
